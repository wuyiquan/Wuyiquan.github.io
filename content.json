{"meta":{"title":"Wu's Blog","subtitle":"不定时更新","description":"一个帅哥","author":"Yiquan Wu","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"","slug":"本周摘要","date":"2019-09-28T14:26:09.057Z","updated":"2019-09-28T14:26:09.057Z","comments":true,"path":"2019/09/28/本周摘要/","link":"","permalink":"http://yoursite.com/2019/09/28/本周摘要/","excerpt":"","text":"本周摘要 实现了TextCNN模型，并在本金诉求上进行了分类预测。 论文阅读为主 本周详细进展 baseline实现 如图所示由于数据分布的不均匀，每个诉求的同意率都很高，且不同意的样本太少了，训练的效果难以保证。 下图是训练的截图： 下图是测试的结果（199:1的同意：不同意比）： 因此这个模型不能作为我们的baseline来用，急需解决数据不均衡的问题。 研读了两篇司法《Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions》、《Learning to Predict Charges for Criminal Cases with LegalBasis》 阅读论文时，发现了一个文书网http://wenshu.court.gov.cn/。网站给了下载的接口，但不知为何不能下载，想到用爬虫，但室友说最近杭州抓了一批爬虫的人进去，敏感时期还是先不爬了。。。 下周计划 继续实现其他baseline。 整理逻辑图，用与或函数来复现逻辑图。 论文阅读，继续关注其他人在司法领域文本生成（判决预测）的方法。 国庆后去园区线下同步一次进展。","categories":[],"tags":[]},{"title":"","slug":"Graph-embedding思考","date":"2019-06-28T08:50:41.438Z","updated":"2019-07-03T10:17:52.298Z","comments":true,"path":"2019/06/28/Graph-embedding思考/","link":"","permalink":"http://yoursite.com/2019/06/28/Graph-embedding思考/","excerpt":"","text":"常见的应用领域 node classfication link prediction clustering visualization 两种graph-embedding embedding node embedding graph embedding貌似都用在node数量很多的情况下，我们这里好像可以直接用d=|V|？ 多数KG都是三元组，两个entity和一个relation，也叫一个fact 文本生成是否可以纯粹依靠KG？ KG多是以entity为主体的问题 输入文本的entity是否易于提取 entity之间的关系是否明确且有价值 ###还是作为attention的组成部分，找entity的有关系的entity对应的词？ metrics output complexity, diversity and semantic correctness","categories":[],"tags":[]},{"title":"","slug":"BELU和ROUGE","date":"2019-06-28T03:07:11.532Z","updated":"2019-06-28T03:46:45.228Z","comments":true,"path":"2019/06/28/BELU和ROUGE/","link":"","permalink":"http://yoursite.com/2019/06/28/BELU和ROUGE/","excerpt":"","text":"BELU 用处：对一个生成语句进行打分。 统计单位为unigram、bigram、trigram、4gram，将四个单位的分数求平均，再乘上BP（短句惩罚） 对于重复出现的词，有一个clip操作，即只取到参考句子中最多的次数为止。 ROUGE 对摘要进行打分 用Recall的思想 其中，n-gram表示n元词，{Ref Summaries}表示参考摘要，即事先获得的标准摘要，Countmatch(n-gram)表示系统摘要和参考摘要中同时出现n-gram的个数，Count(n-gram)则表示参考摘要中出现的n- gram个数。","categories":[],"tags":[]},{"title":"","slug":"faq提取","date":"2019-05-08T07:31:46.339Z","updated":"2019-05-08T07:31:46.339Z","comments":true,"path":"2019/05/08/faq提取/","link":"","permalink":"http://yoursite.com/2019/05/08/faq提取/","excerpt":"","text":"###任务描述 从已有的数据库中抽出所有”债权债务纠纷”领域的queries，并从中提取出FAQ。 ###操作流程 利用Elasticsearch的search操作和游标，滚动提取了所有”债权债务纠纷”领域的queries，一共有27w+，保存至csv，保留了’question_content’和’intent’两个attribute。 根据每个问题的’intent’，再将所有queries分类，如果一个query的intent值为[]，则分到default类中，分类结果及大小如下： 1.3M 债务人骗钱怎么办.csv 1.8M 材料合规性.csv 2.0M 抵押.csv 2.1M 网贷.csv 2.5M 无偿还能力怎么办.csv 2.6M 债务人失踪怎么办.csv 3.8M 担保.csv 4.0K 债务人死亡怎么办.csv 4.0K 债权人死亡怎么办.csv 4.0K 暴力讨债怎么办.csv 5.5M 欠钱不还怎么办.csv 25M default.csv 412K 费用合理性.csv 524K 信用卡纠纷.csv 对于每个类的queries，进行tfidf+kmeans聚类，取k值为总query数的1/30，得到聚类中心后，用score函数得到每个句子距离中心的距离，以此得到每个中心最近的query。 最后一共得到了9583个faq。 路径为/home/griffin.wyq/elasearch/data/result/faq-result.csv，有’sentence’和’score’两列，用’\\t’分割","categories":[],"tags":[]},{"title":"","slug":"SVMforMulticlass","date":"2019-03-08T07:34:36.392Z","updated":"2019-03-08T08:58:50.213Z","comments":true,"path":"2019/03/08/SVMforMulticlass/","link":"","permalink":"http://yoursite.com/2019/03/08/SVMforMulticlass/","excerpt":"","text":"SVM multiclass一层标签count： 给每个label打上索引id 找到每个标签关联度最强的词与词组 ###’借款未到期’: . Most correlated unigrams: . 四年 . 解除合同 . Most correlated bigrams: . 借条 一年 . 没有 到期 ###’债权人资格’: . Most correlated unigrams: . 债权 . 陈冲 . Most correlated bigrams: . 债权 原告 . 债权 转让 ###’刑民交叉’: . Most correlated unigrams: . 公安机关 . 诈骗罪 . Most correlated bigrams: . 徐慧文 行为 . 构成 诈骗罪 ###’利息’: . Most correlated unigrams: . 约定 . 利息 . Most correlated bigrams: . 支付 利息 . 约定 利息 ###’噪音’: . Most correlated unigrams: . 证据 . 被上诉人 . Most correlated bigrams: . 证据 三性 . 三性 异议 ###’夫妻共同债务诉求’: . Most correlated unigrams: . 共同 . 夫妻 . Most correlated bigrams: . 共同 债务 . 夫妻 共同 ###’套路贷’: . Most correlated unigrams: . 4500 . 放贷 . Most correlated bigrams: . 一起 放贷 . 放贷 出去 ###’担保责任’: . Most correlated unigrams: . 担保人 . 担保 . Most correlated bigrams: . 担保 期限 . 承担 担保责任 ###’本金争议’: . Most correlated unigrams: . 万元 . 利息 . Most correlated bigrams: . 支付 利息 . 约定 利息 ###’虚假诉讼’: . Most correlated unigrams: . 诉讼 . 虚假 . Most correlated bigrams: . 存在 虚假 . 虚假 诉讼 ###’诉讼时效’: . Most correlated unigrams: . 时效 . 诉讼时效 . Most correlated bigrams: . 诉讼时效 是否 . 超过 诉讼时效 ###’违约损失’: . Most correlated unigrams: . 律师费 . 违约金 . Most correlated bigrams: . 实现 债权 . 逾期 利息 四种模型的准确率","categories":[],"tags":[]},{"title":"","slug":"分类问题常见的evaluation metrics","date":"2019-03-07T06:50:29.873Z","updated":"2019-03-07T15:50:00.495Z","comments":true,"path":"2019/03/07/分类问题常见的evaluation metrics/","link":"","permalink":"http://yoursite.com/2019/03/07/分类问题常见的evaluation metrics/","excerpt":"","text":"分类问题常见的evaluation metrics把结果分为四种 本类样本被分到了本类中 TP 本类样本被分到了错误类 FP 其他类样本被分到了本类 FN 其他类样本被分到了其他类 TN 准确率（Accuracy） 精确率（Precision) 召回率 （Recall） F-measure 通常Beta取1，即$$F_{1}$$。 ##多类的情况 multilabel 或者 multiclass 时，会用到宏平均和微平均。 宏平均会受小类别较大的影响。一方面，它可以使小类更多地参与计算，另一方面，也会使得一些不重要的小类影响评估结果。其计算方式如下： 而微平均是对数据集中的每一个实例不分类别进行统计建立全局混淆矩阵，会把所有的样本放到一起进行计算，因此不会在意具体某一类样本的个数。 参考： https://blog.csdn.net/u014665013/article/details/80545180#F_1 https://blog.csdn.net/baidu_38945893/article/details/82141975?utm_source=blogxgwz2 吴亦全 2019.3","categories":[],"tags":[]},{"title":"","slug":"读书报告003","date":"2019-02-28T02:47:06.795Z","updated":"2019-02-28T06:13:41.481Z","comments":true,"path":"2019/02/28/读书报告003/","link":"","permalink":"http://yoursite.com/2019/02/28/读书报告003/","excerpt":"","text":"##HINET: HIERARCHICAL CLASSIFICATION WITH NEURALN ETWORK 1、多层标签用多层的神经网络来表示，第n层的第m个node，表示n级标签中的第m个。 2、利用downpour的方法，来获得候选trace的MAP，每一层都有一个stop node，用来结束trace。最后选取MAP最大的trace作为结果。","categories":[],"tags":[]},{"title":"","slug":"读书报告002","date":"2019-02-27T03:28:45.548Z","updated":"2019-02-28T02:46:42.047Z","comments":true,"path":"2019/02/27/读书报告002/","link":"","permalink":"http://yoursite.com/2019/02/27/读书报告002/","excerpt":"","text":"Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions 1、存在事实描述中，动机表述不明的情况，直接缩句效果一般。 2、利用了罪名标签，辅助本院认为的解释。 we only focus on generating the part of rationales in court views 3、","categories":[],"tags":[]},{"title":"","slug":"读书报告001","date":"2019-02-25T12:35:26.412Z","updated":"2019-02-28T02:46:56.644Z","comments":true,"path":"2019/02/25/读书报告001/","link":"","permalink":"http://yoursite.com/2019/02/25/读书报告001/","excerpt":"","text":"Automatic Judgment Prediction via Legal Reading Comprehension 1.数据都是无监督的，每个case都有五个相关法条做参考，注释掉了无用信息，如姓名等。 2.是01预测 3.创新点在于用了RC的理论，然后是double pair。诉称和法条分别与事实认定进行计算，得到一个中间状态序列，并用这个中间状态序列来预测0或1。 These models employ various attention mechanism to model the interaction between passage and query.","categories":[],"tags":[]},{"title":"TF-IDF","slug":"TF-IDF","date":"2019-01-11T07:53:50.000Z","updated":"2019-03-07T13:37:18.996Z","comments":true,"path":"2019/01/11/TF-IDF/","link":"","permalink":"http://yoursite.com/2019/01/11/TF-IDF/","excerpt":"","text":"最近做的项目需要无监督的抽取一些标签，本来想粗暴的用词频来抽取，后来同事说可以试试TF-IDF，我就自学了一下，现做摘记如下： TF-IDF全称为Term Frequency - Inverse Documentation Frequency，即词频-逆文档频率，是当前非常常用的一种文本特征的提取方法，在文本信息检索，语意抽取等自然语言处理（NLP）中广泛应用。TF:即词频，定义有很多，这里定义如下：$$TF(w)=\\frac{c_{w}}{c_{total}}{\\tag 1}$$其中，$c_{w}$指在目标文档中某个词出现的次数，$c_{total}$指目标文档所有词出现的次数之和（也就是一共有几个词）。 我一开始的方法，就是指用TF做排序，然后人工去过滤一些stop word，但这样效率太低了。 IDF:逆文档频率，这个逆文档好像ads课上讲过，意思是有一个词，然后去找哪些文档里出现了这个词，这与常识中的查找思路正好相反，因此有个逆，其定义如下：$$IDF(w)=log\\frac{N_{total}+1}{N_{w}+1}{\\tag 2}$$其中，$N_{total}$指语料库里一共有多少文档，$N_{w}​$指某个词一共出现在了多少文档。这里之所以加1，是为了防止分母为0的情况出现。 TF-IDF就是TF*IDF，然后排序，非常的简单。 它的优点是可以过滤掉一些在所有文档中都频繁出现的词语，即stop word，同时保留我们需要的一些能够代表文档的关键词。 缺点是可能某一类文档占总语料库的比例较大时，可能会使一些关键词被误认为是stop word. python中，有一个Scikit-learn包，包含了tf-idf方法，我们可以直接拿来用。 主要用到的函数有两个： CountVectorizer，用来将语料库中的词语转化为词频矩阵。 TfidfTransformer，根据词频得到TF-IDF。 是","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2019-01-11T07:22:47.248Z","updated":"2019-01-11T07:22:47.248Z","comments":true,"path":"2019/01/11/hello-world/","link":"","permalink":"http://yoursite.com/2019/01/11/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}